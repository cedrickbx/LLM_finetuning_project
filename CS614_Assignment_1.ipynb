{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS614 Assignment 1 - LLM Training Code"
      ],
      "metadata": {
        "id": "O9Oszc0t1zmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate datasets\n",
        "!pip install bert_score rouge_score"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t7yVNUDnIe9",
        "outputId": "b363800a-9159-4a8c-8021-3b672fe90562"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert_score) (4.56.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert_score) (25.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.35.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (3.2.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (2025.8.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert_score) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    from huggingface_hub import login\n",
        "    from google.colab import userdata\n",
        "\n",
        "    # Load the token from Colab secrets\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "    # Log in to Hugging Face\n",
        "    login(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "goEfIobW0sgg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "import evaluate, torch, numpy as np\n",
        "from datasets import load_dataset, get_dataset_split_names"
      ],
      "metadata": {
        "id": "QB76UU8y2pjP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset**:\n",
        "The dataset is obtained from https://huggingface.co/datasets/abisee/cnn_dailymail. It contains more than three thousand news articles from CNN and Daily Mail, and used for extractive and abstractive summarisation."
      ],
      "metadata": {
        "id": "I9Wc2ndtaiOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task:**\n",
        "Summarise news articles using the selected LLM."
      ],
      "metadata": {
        "id": "l5wbj4wQmL0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\") #use most common config\n"
      ],
      "metadata": {
        "id": "HPRcQcBwabmS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get split names\n",
        "get_dataset_split_names(\"abisee/cnn_dailymail\", \"3.0.0\")"
      ],
      "metadata": {
        "id": "euHo06Nk9QlM",
        "outputId": "f85b536e-1854-43b9-ea15-1c0d1afdee7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'validation', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load train, validation and test dataset\n",
        "train = ds[\"train\"].shuffle(seed=42)\n",
        "val = ds[\"validation\"].shuffle(seed=42)\n",
        "test = ds[\"test\"].shuffle(seed=42)\n",
        "\n",
        "#load small subset to speed up training\n",
        "small_train_dataset = train.select(range(1000))\n",
        "small_eval_dataset = val.select(range(1000))"
      ],
      "metadata": {
        "id": "BFzEHl-K-J1N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check random subset of data\n",
        "small_train_dataset[19]"
      ],
      "metadata": {
        "id": "zk8gU5Bq9dTT",
        "outputId": "afae7580-484b-4c4d-bb40-2f22cef92381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': '(CNN) -- Four suspects are sought in connection with the shooting death over the weekend of a Houston, Texas, doctor, Austin County authorities said Monday. Dr. Jorge Mario Gonzales was found shot to death at his ranch in rural Texas on Saturday, police say. Dr. Jorge Mario Gonzalez, 56, was chief of the critical care section at Houston\\'s Methodist Hospital and \"a pulmonary medicine leader,\" according to the hospital system\\'s Web site. He was found dead Saturday when deputies responded to a 911 call of a burglary in progress shortly after noon, said Austin County Sheriff\\'s Office spokesman Sgt. Paul Faircloth. The responding officer was met by vehicles leaving the location, Faircloth said, and a person in one vehicle fired on the officer. The officer and his car were not struck, and the officer did not return fire, Faircloth said. The officer was able to provide a detailed description of the vehicles, he said. At the home, which Faircloth said is in a rural, wooded and isolated area, officers found Gonzalez shot to death and another person wounded. The second victim was airlifted to an Austin, Texas, hospital.  Watch Dr. Gonzalez\\'s son talk about his father » . Gonzalez\\'s wife and small child were found unharmed inside the home, Faircloth said. CNN affiliate KHOU identified the woman as Charleen Gonzalez, 29, and the couple\\'s 2-year-old son, and reported the two hid in a closet. Authorities do not know whether the incident was a burglary or an intended home invasion, Faircloth said, and \"we do not know if this is random or targeted.\" Several leads were being followed Monday morning, he said, and numerous agencies were involved in the investigation. The motive for the killing had not been determined on Monday. The slaying took place at Gonzalez\\'s ranch outside Bellville, Texas, said Lisa Block, spokeswoman for the Texas Department of Public Safety. Gonzalez, his wife and child arrived at the ranch about 11 a.m. Saturday, she said, and \"the suspects were at the house when they arrived.\" Gonzalez\\'s wife ran inside with the child and called 911, she said. Ranch worker Noel Galvan was the second victim, Block said. He was listed in critical condition, she said. Faircloth said earlier Monday five suspects were being sought, but later said police were seeking four. The vehicles seen leaving the home were a late \\'90s white Ford F-150 pickup, occupied by two Hispanic males, Faircloth said, and a red Honda or Acura with dark tinted windows sitting low to the ground, with one Hispanic male inside. The shots were fired from the white pickup, he said. Another vehicle mentioned earlier Monday was a two-toned silver and black Ford F-150 that had two Hispanic males inside. Faircloth said Monday afternoon that vehicle had been located and was not thought to be involved. However, police released a video of a gray Lexus on Monday, and would like to question its owners, Faircloth said. The drivers are believed to be an older couple. The car was seen before the officer encountered the white and red vehicles. \"The manhunt continues on the ground,\" Faircloth said. The suspects are considered armed and dangerous, he said. Faircloth said he had no information on whether the home had surveillance equipment. Family members told KHOU that Gonzalez went to the ranch nearly every weekend. \"It\\'s deeply saddening for all of us,\" an older son of Gonzalez, Juan Mauricio Gonzalez, told KHOU. \"We are a tight-knit family and he was just a perfect man, a perfect father and a great physician.\" The Methodist Hospital System said Gonzalez will be missed, \"both as a friend and an outstanding clinician and researcher. Our prayers and thoughts go out to his family during this tragedy.\" \"This man had nothing to do with anybody,\" Juan Gonzalez told KHOU. \"He was a peaceful man. He was a wise man. He was just here to make people better and nothing else.\" A reward totaling $26,000 was offered for information in the case leading to an arrest. CNN\\'s Melanie Whitley contributed to this report.',\n",
              " 'highlights': \"Suspects were at doctor's house when he, wife and child arrived, police say .\\nPolice responded to 911 call of burglary at rural home of Houston, Texas, doctor .\\nPolice found Dr. Jorge Mario Gonzalez shot to death and a ranch worker badly injured .\\nGonzalez's wife and toddler found unharmed; they reportedly hid in a closet .\",\n",
              " 'id': 'f225d5678bb139b4e3d296fd0b5d52c759446078'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the attributes (features) of dataset\n",
        "train.features"
      ],
      "metadata": {
        "id": "laBEDq-M5gTI",
        "outputId": "b71852e9-5a26-4f3e-d527-76f04dd0961b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': Value('string'),\n",
              " 'highlights': Value('string'),\n",
              " 'id': Value('string')}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`article`: Original article\n",
        "<br>`highlights`: Summary reference"
      ],
      "metadata": {
        "id": "FJF20ag2-O1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Model:**\n",
        "\n",
        "Since data privacy is not a key concern in this task, an open-source model is used. A small model (1B) is used to keep cost low."
      ],
      "metadata": {
        "id": "DbB-xSr6cdUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/gemma-3-1b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).eval() #disable dropout\n",
        "bert_score = evaluate.load(\"bertscore\")\n",
        "rouge_score = evaluate.load(\"rouge\", use_aggregator=True)"
      ],
      "metadata": {
        "id": "zfflMPOFa5fm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model before training\n",
        "def eval_model(batch):\n",
        "  articles = [f\"Summarise this into one paragraph: {article}\\nSummary:\\n\" for article in batch[\"article\"]]\n",
        "  tokens = tokenizer.batch_encode(batch, return_tensors=\"pt\").to(\"cuda\")\n",
        "  with torch.no_grad():\n",
        "    response = model.generate(tokens, max_new_tokens=256, use_cache=True)\n",
        "  batch[\"summary\"] = tokenizer.batch_decode(response, skip_special_tokens=True)\n",
        "  return batch\n",
        "\n",
        "summaries = small_eval_dataset.map(eval_model, batched=True, batch_size=8)\n",
        "print(summaries)\n"
      ],
      "metadata": {
        "id": "uxylGbwO2k4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create functions to tokenize and compute evaluation metric\n",
        "def tokenize_text(text):\n",
        "  return tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  logits, labels = eval_preds\n",
        "  preds = np.argmax(logits, axis=1)\n",
        "  rouge_score.compute(predictions=preds, references=val[\"highlights\"])\n",
        "  bert_score.compute(predictions=preds, references=val[\"highlights\"], model_type = \"roberta-large\")\n",
        "  return bert_score, rouge_score\n",
        "\n",
        "\n",
        "  return rouge_score\n",
        "# def compute_metrics(eval_pred):\n",
        "#   logits, labels = eval_pred\n",
        "#   predictions = np.argmax(logits, axis=1)\n",
        "#   return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVKIENMmmAzK",
        "outputId": "cf3ad166-8b01-4130-c403-0077d205c400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: ROME, Italy (CNN) -- The garbage crisis in Naples encompasses the worst Italian clichés, and in particular those of the southern part of this lovely peninsula: mismanagement, political interference, mafia profiteering and the ability of those responsible to deflect the attention and the blame elsewhere. Naples has had problems in finding sites for municipal dumps -- now workers have stopped collecting trash. There is a popular saying here that roughly goes like this: everybody is competent enough (to find a solution) but nobody is responsible (for actually carrying it out). In many parts of the world waste disposal is a business -- and usually it is a good business. Garbage can be transformed into various sources of energy and then sold for a profit. In Naples, garbage is also good business, but in the sense that millions, if not billions, of euros have been wasted -- and nobody really knows how. The problem is as old and ugly as rotten trash. The region's dumps reached full capacity more than a decade ago, and since then a state of emergency has been declared every year. Eight different commissioners have been appointed, but they have all failed to solve the problem. State of emergency means government money: €1.8 billion (more than $2.5 billion) in emergency funds have been devolved to deal with the problem. It is still difficult to find out where or how that money has been spent. Incinerators that were supposed to be built were never finished, either because the companies in charge of constructing them could not finish the job, or else because magistrates stopped the work, pending ongoing criminal investigations into alleged mafia involvement. One Italian newspaper suggested that a good 20% of the money went to pay for the salaries of those in charge of coming up with a solution to the problem. More worrying perhaps, is another suggestion: that the local mafia, known as the Camorra, is taking advantage of the situation. As the crisis has worsened over the years, so the Camorra's profits, estimated now at around €1 billion (roughly $1.45 billion), are alleged to have increased. How does the local mafia make money? The Naples prosecutor in charge of environmental crimes says city government officials use the state of emergency to quickly award contracts which otherwise would have to be checked by complicated anti-racketeering legislation. Once they receive the money, companies linked to the underworld dispose of the waste either in the open or, ironically, at regular city dumps, even if they are overflowing. The mafia clans have now managed to burrow their way so deeply into the system that every attempt to fix the problem has proved futile. But why are citizens protesting now? Well, the government wants to re-open a previously shut dump to dispose of 3,700 tons of waste which is laying in the streets of Naples and surrounding areas. The problem is that when the site was closed years ago, locals were promised that a golf course would be built there. As a result, many residents invested savings to construct apartments and residences in the vicinity -- in some cases just a few yards away from the site. They are now waking up to a mountain of trash instead of 18 holes. A rotten deal indeed. E-mail to a friend .\n",
            "Summary: Rubbish is piling up on the streets of Naples, with municipal dumps full . Many commentators question the role of the local mafia in the award of contracts . More than $2.5B in emergency funds has been spent on the problem over the years . One dump was going to be a golf course -- residents furious it is being re-opened .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Q8Q9eQJcMIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation: BERTScore & ROUGE\n",
        "Both BERTScore and ROUGE will be used to evaluate the model's performance.\n",
        "ROUGE-L will evaluate the model's performance based on longest common subsequence based scoring. while BERTScore will be used to evaluate paraphrasing and semantic similarity of the reference text and their corresponding summary, which can be a more accurate representation of the model's performance."
      ],
      "metadata": {
        "id": "5b3Tx_8n2MKT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HLpUWuUq2iYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    report_to=\"none\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01, #regularisation - same effect as dropout (reduce overfitting by reducing weights)\n",
        "    warmup_ratio=0.1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.999,\n",
        "    adam_epsilon=1e-8,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    output_dir=\"test_trainer\",\n",
        "    eval_strategy=\"epoch\")"
      ],
      "metadata": {
        "id": "R_lG_Cbrl6Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training based on hyperparameters stated in previous cell\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        ")"
      ],
      "metadata": {
        "id": "vyJ1-GmtmuQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}